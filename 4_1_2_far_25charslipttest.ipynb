{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "835e62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scp -P 8787 .\\95charimg_scale_250.zip e806@163.13.136.85:/home/e806/hoiee\n",
    "\n",
    "# Standard libraries\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import shutil\n",
    "import os \n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# Third-party libraries\n",
    "#torch libraries\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tabula\n",
    "import aircv as ac\n",
    "import pyautogui\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Utilities\n",
    "from functools import cmp_to_key\n",
    "from utils import *\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bf4122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94be7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 100 #訓練的迭代次數，設為100。一個迭代代表在訓練過程中完整遍歷整個資料集一次。\n",
    "batch_size = 5 #每個批次的樣本數量，用於訓練。設為128，這意味著模型會在處理每個包含128個樣本的批次後更新參數。\n",
    "capacity = 64 #VAE模型中隱藏層的容量，設為64。該參數決定了隱藏層中神經元的數量。\n",
    "learning_rate = 1e-3 #訓練過程中優化器使用的學習率。設為0.001（1e-3），控制優化算法的步幅大小。\n",
    "variational_beta = 1 #在VAE損失函數中應用於Kullback-Leibler（KL）散度項目的權重。設為1，表示模型對重構損失和KL散度賦予相等的重要性。\n",
    "use_gpu = True #一個布爾標誌，指示是否在訓練時使用GPU（如果可用）。設為True，如果有兼容的GPU存在，則啟用GPU加速。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 25, 100, 100, 3)\n",
      "(43, 5)\n",
      "(43, 25, 3, 100, 100)\n",
      "(43, 5)\n",
      "(40, 25, 3, 100, 100)\n",
      "(3, 25, 3, 100, 100)\n",
      "(40, 5)\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "x_file = \"./4_1_x.npy\"\n",
    "y_file = \"./4_1_y.npy\"\n",
    "\n",
    "# 讀取x檔案\n",
    "# 讀取y檔案\n",
    "x_data = np.load(x_file, allow_pickle=True).astype('float')\n",
    "y_data = np.load(y_file, allow_pickle=True).astype('float')\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data = np.transpose(x_data, (0, 1, 4, 2, 3))\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "\n",
    "train_data_x = x_data[0:40,:]\n",
    "test_data_x = x_data[40:44,:]\n",
    "train_data_y = y_data[0:40,:]\n",
    "test_data_y = y_data[40:44,:]\n",
    "\n",
    "print(train_data_x.shape)\n",
    "print(test_data_x.shape)\n",
    "print(train_data_y.shape)\n",
    "print(test_data_y.shape)\n",
    "\n",
    "# 將資料轉換為Tensor類型\n",
    "train_x_tensor = torch.Tensor(train_data_x)\n",
    "train_y_tensor = torch.Tensor(train_data_y)\n",
    "test_x_tensor = torch.Tensor(test_data_x)\n",
    "test_y_tensor = torch.Tensor(test_data_y)\n",
    "\n",
    "# 建立訓練集和測試集的TensorDataset\n",
    "train_dataset = TensorDataset(train_x_tensor,train_y_tensor)\n",
    "test_dataset = TensorDataset(test_x_tensor,test_y_tensor)\n",
    "\n",
    "# 設定批次大小\n",
    "#batch_size = 2\n",
    "\n",
    "# 建立訓練集和測試集的DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc998436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.relu3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "class ModifiedMultiConvNet(nn.Module):\n",
    "    def __init__(self, num_modules=25):\n",
    "        super(ModifiedMultiConvNet, self).__init__()\n",
    "        \n",
    "        # Create a list of ConvModules\n",
    "        self.modules_list = nn.ModuleList([CNN() for _ in range(num_modules)])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(25*12*12*128, 5)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        assert len(inputs) == len(self.modules_list), \"Number of inputs should match number of modules\"\n",
    "        \n",
    "        outputs = []\n",
    "        for i, module in enumerate(self.modules_list):\n",
    "            outputs.append(module(inputs[i]))\n",
    "\n",
    "        concatenated_output = torch.cat(outputs, dim=1)  # Concatenate along the channel dimension\n",
    "        flattened_output = self.flatten(concatenated_output)  \n",
    "        final_output = self.fc(flattened_output)  # Pass through the FC layer\n",
    "\n",
    "        return final_output\n",
    "\n",
    "# Create an instance of the modified model with 25 modules\n",
    "model = ModifiedMultiConvNet().to('cuda')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a0264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 100] average reconstruction error: 1559731.688344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 29.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 100] average reconstruction error: 936.805479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 100] average reconstruction error: 374.777497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 100] average reconstruction error: 315.607720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 32.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 100] average reconstruction error: 416.101749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 100] average reconstruction error: 318.033396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:00<00:01, 13.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m# backpropagation\u001b[39;00m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 29\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     30\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     32\u001b[0m train_loss_avg[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\evan6\\.conda\\envs\\NTUNHS\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\evan6\\.conda\\envs\\NTUNHS\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "\n",
    "train_loss_avg = []\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "\n",
    "    # 使用 tqdm 包裝 train_dataloader，顯示進度條\n",
    "    for x,y in tqdm(train_dataloader):\n",
    "        x  = x.to(\"cuda\")\n",
    "        y  =  y.to(\"cuda\")\n",
    "        # Create dummy inputs for each of the 25 modules\n",
    "        # Forward pass using the modified model\n",
    "        pre_y = model([x[:,i] for i in range(25)])\n",
    "\n",
    "        loss = criterion(pre_y,y)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_avg[-1] += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    train_loss_avg[-1] /= num_batches\n",
    "    print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c467397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.save(model.state_dict(), '4_1_far4325model.pt')\n",
    "model.load_state_dict(torch.load('./weight/4_1_far4325model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a84a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25, 3, 100, 100])\n",
      "tensor([[103.9651,  89.1274, 104.7516, 108.5049, 115.3910]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "104.34801\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "train_data_x = path_cropimg_to_eval(path = './337556(1).jpg') \n",
    "train_x_tensor = torch.Tensor(train_data_x)\n",
    "print(train_x_tensor.shape)\n",
    "\n",
    "\n",
    "x = train_x_tensor.to(\"cuda\")\n",
    "pre_y = model([x[:,i] for i in range(25)])\n",
    "\n",
    "print(pre_y)\n",
    "a= pre_y.cpu()\n",
    "print(np.mean(a[0].detach().numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55746540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
